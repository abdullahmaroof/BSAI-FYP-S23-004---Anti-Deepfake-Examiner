{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74e23295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version: 2.8.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "print(\"Tensorflow version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83f4bdc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "print(tf.config.list_physical_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2e2f81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = [128, 128]\n",
    "train_path = 'D://FYP Project//Dataset//Train'\n",
    "valid_path = 'D://FYP Project//Dataset//Validation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50235b1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data:\n",
      "70001 Fake images.\n",
      "70001 Real images.\n",
      "\n",
      "Validation Data:\n",
      "19641 Fake images.\n",
      "19787 Real images.\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Data:\")\n",
    "for expression in os.listdir(\"D://FYP Project//Dataset//Train\"):\n",
    "    print(str(len(os.listdir(\"D://FYP Project//Dataset//Train//\"+expression))) + \" \" + expression + \" images.\")\n",
    "print(\"\\nValidation Data:\")    \n",
    "for expression in os.listdir(\"D://FYP Project//Dataset//Validation\"):\n",
    "    print(str(len(os.listdir(\"D://FYP Project//Dataset//Validation//\"+expression))) + \" \" + expression + \" images.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "888b2d2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 140002 images belonging to 2 classes.\n",
      "Found 39428 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "ig = ImageDataGenerator(rescale=1./255.)\n",
    "train_flow = ig.flow_from_directory(\n",
    "    'D://FYP Project//Dataset//Train',\n",
    "    target_size=(128, 128),\n",
    "    batch_size=64,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "ig1 = ImageDataGenerator(rescale=1./255.)\n",
    "valid_flow = ig1.flow_from_directory(\n",
    "    'D://FYP Project//Dataset//Validation',\n",
    "    target_size=(128, 128),\n",
    "    batch_size=64,\n",
    "    class_mode='categorical'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c6c3390",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Fake': 0, 'Real': 1}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_flow.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9beee31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resnet50 (Functional)       (None, 4, 4, 2048)        23587712  \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 2048)             0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               1049088   \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 512)              2048      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 1026      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 24,639,874\n",
      "Trainable params: 24,585,730\n",
      "Non-trainable params: 54,144\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ABDULLAH\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "input_shape=(128,128,3)\n",
    "batch_size=64\n",
    "\n",
    "\n",
    "def build_model():\n",
    "    densenet = ResNet50(\n",
    "                        weights='imagenet',\n",
    "                        include_top=False,\n",
    "                        input_shape=input_shape\n",
    "                        )\n",
    "    model = Sequential([densenet,\n",
    "                        layers.GlobalAveragePooling2D(),\n",
    "                        layers.Dense(512,activation='relu'),\n",
    "                        layers.BatchNormalization(),\n",
    "                        layers.Dense(2, activation='softmax')\n",
    "                        ])\n",
    "    model.compile(optimizer=Adam(lr=0.001),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy']\n",
    "                 )\n",
    "    return model\n",
    "\n",
    "\n",
    "model = build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5924bc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "80/80 [==============================] - 966s 12s/step - loss: 0.3819 - accuracy: 0.8604 - val_loss: 1.4527 - val_accuracy: 0.5019\n",
      "Epoch 2/50\n",
      "80/80 [==============================] - 630s 8s/step - loss: 0.1582 - accuracy: 0.9387 - val_loss: 0.8878 - val_accuracy: 0.5019\n",
      "Epoch 3/50\n",
      "80/80 [==============================] - 588s 7s/step - loss: 0.1329 - accuracy: 0.9465 - val_loss: 0.7167 - val_accuracy: 0.5019\n",
      "Epoch 4/50\n",
      "80/80 [==============================] - 431s 5s/step - loss: 0.1365 - accuracy: 0.9479 - val_loss: 0.9925 - val_accuracy: 0.5019\n",
      "Epoch 5/50\n",
      "80/80 [==============================] - 431s 5s/step - loss: 0.1161 - accuracy: 0.9529 - val_loss: 0.8173 - val_accuracy: 0.5020\n",
      "Epoch 6/50\n",
      "80/80 [==============================] - 431s 5s/step - loss: 0.1107 - accuracy: 0.9553 - val_loss: 0.6557 - val_accuracy: 0.5311\n",
      "Epoch 7/50\n",
      "61/80 [=====================>........] - ETA: 29s - loss: 0.0928 - accuracy: 0.9641"
     ]
    }
   ],
   "source": [
    "r = model.fit(\n",
    "  train_flow,\n",
    "  validation_data=valid_flow,\n",
    "  epochs=50,\n",
    "  steps_per_epoch=80,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce4243e",
   "metadata": {},
   "outputs": [],
   "source": [
    "r.save('ResNet_50trainedmodel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4a23ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4f4a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(r.history['loss'], label='train loss')\n",
    "plt.plot(r.history['val_loss'], label='val loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig('ResnetLossVal_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4060714e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(r.history['accuracy'], label='train acc')\n",
    "plt.plot(r.history['val_accuracy'], label='val acc')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig('ResnetAccVal_acc')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
